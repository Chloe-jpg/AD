{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from imblearn.metrics import sensitivity_specificity_support as sss\n",
    "from sklearn.metrics import  f1_score, precision_score, recall_score, accuracy_score, roc_curve, auc, roc_auc_score, confusion_matrix as CM\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input, Dense, Multiply,add,concatenate,Conv3D,GlobalAveragePooling3D,  MaxPooling3D, LeakyReLU, BatchNormalization, Dropout, Flatten, Activation, Reshape,  Conv3DTranspose, UpSampling3D\n",
    "from tensorflow.keras.regularizers import l2, l1, l1_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cretae the binary input \n",
    "def data_filter(data, label, exclu):\n",
    "    idx = np.where(label!= exclu)[0]\n",
    "    #print(len(idx))\n",
    "    data_new = data[idx]\n",
    "    label_new = label[idx]\n",
    "    #print(data_new.shape)\n",
    "    print(np.unique(label_new, return_counts=True))\n",
    "    return data_new, label_new\n",
    "\n",
    "# onehot encode labels for binary classifications\n",
    "def onehot_bi(y):\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    y = y.reshape(len(y), 1)\n",
    "    y_encoded = onehot_encoder.fit_transform(y)\n",
    "    return y_encoded\n",
    "\n",
    "# onehot encode labels for 3-way classifications\n",
    "def onehot_tri(y):\n",
    "    from keras.utils import to_categorical\n",
    "    return to_categorical(y)\n",
    "\n",
    "# view the distribution of class labels of the input data\n",
    "def showpercentage(array):\n",
    "    pcn = array[1][0]/np.sum(array[1])\n",
    "    pmci = array[1][1]/np.sum(array[1])\n",
    "    pad = array[1][2]/np.sum(array[1])\n",
    "    print(str(pad) + \" percent of the data has AD label\")\n",
    "    print(str(pcn) + \" percent of the data has CN label\")\n",
    "    print(str(pmci) + \" percent of the data has MCI label\")\n",
    "# visualizatio of model traning and model performance \n",
    "\n",
    "# visualize the training and validation performance\n",
    "def plot_history(data_list, label_list, title, ylabel, name):\n",
    "\n",
    "    epochs = range(1, len(data_list[0]) + 1)\n",
    "\n",
    "    for data, label in zip(data_list, label_list):\n",
    "        plt.plot(epochs, data, label=label)\n",
    "    plt.title(title, pad = 10, fontsize='large')\n",
    "    plt.xlabel('Epochs', labelpad=10)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "    plt.savefig(name, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "#%%\n",
    "\n",
    "# model evaluation\n",
    "    \n",
    "# evaluate model performance - binary classifications\n",
    "def evaluate_binary(X_test, y_test, model, name):\n",
    "    \n",
    "    test_y_prob = model.predict(X_test)\n",
    "    print(test_y_prob)\n",
    "    test_y_pred = np.argmax(test_y_prob, axis = 1)\n",
    "    test_y_true = np.argmax(y_test, axis = 1) \n",
    "    # accuracy\n",
    "    \n",
    "    loss, acc = model.evaluate(X_test, y_test)\n",
    "    # AUC\n",
    "    pos_prob = test_y_prob[:,1]\n",
    "    auc_score = roc_auc_score(test_y_true, pos_prob)\n",
    "    # precision, recall, specificity, and f1_score\n",
    "    p = precision_score(test_y_true, test_y_pred)\n",
    "    r = recall_score(test_y_true, test_y_pred)\n",
    "    f1 = f1_score(test_y_true, test_y_pred)\n",
    "#     sen, spe, _ = sss(test_y_true, test_y_pred, average=\"binary\")\n",
    "    print(test_y_true, test_y_pred)\n",
    "    # print results\n",
    "    print(\"Test accuracy:\", acc)\n",
    "    print(\"Test AUC is: \", auc_score)\n",
    "    print(\"Test confusion matrix: \\n\", CM(test_y_true, test_y_pred))\n",
    "    print(\"Precision: \", p)\n",
    "    print(\"Recall: \", r)\n",
    "#     print(\"Specificity: \", spe)\n",
    "    print(\"f1_score: \", f1)\n",
    "\n",
    "    # plot and save roc curve\n",
    "    pos_prob = test_y_prob[:,1]\n",
    "    fpr, tpr, thresholds = roc_curve(test_y_true, pos_prob)\n",
    "    ns_probs = [0 for _ in range(len(test_y_prob))]\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(test_y_true, ns_probs)\n",
    "    plt.axis([0,1,0,1]) \n",
    "    plt.plot(fpr,tpr, marker = '.', color = 'darkorange', label = 'Model AUC (area = {:.2f})'.format(auc_score)) \n",
    "    plt.plot(ns_fpr, ns_tpr, color = 'royalblue', linestyle='--')\n",
    "    plt.legend()\n",
    "    plt.xlabel('False Positive Rate') \n",
    "    plt.ylabel('True Positive Rate') \n",
    "    plt.savefig(name, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "# evaluate model performance - 3 way classifiations\n",
    "def evaluate_3way(X_test, y_test, model):\n",
    "    test_y_prob = model.predict(X_test)\n",
    "    test_y_pred = np.argmax(test_y_prob, axis = 1)\n",
    "    test_y_true = np.argmax(y_test, axis = 1) \n",
    "    print(test_y_prob)\n",
    "    # accuracy\n",
    "    loss, acc = model.evaluate(X_test, y_test)\n",
    "    # precision, recall, specificity, and f1_score\n",
    "    p = precision_score(test_y_true, test_y_pred, average=\"macro\")\n",
    "    r = recall_score(test_y_true, test_y_pred, average=\"macro\")\n",
    "    f1 = f1_score(test_y_true, test_y_pred, average=\"macro\")\n",
    "#     sen,spe,_ = sss(test_y_true, test_y_pred, average=\"macro\")\n",
    "    print(test_y_true, test_y_pred)\n",
    "    print(\"Test accuracy:\", acc)\n",
    "    print(\"Test confusion matrix: \\n\", CM(test_y_true, test_y_pred))\n",
    "    print(\"Precision: \", p)\n",
    "    print(\"Recall: \", r)\n",
    "#     print(\"Specificity: \", spe)\n",
    "    print(\"f1_score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356, 64, 64, 64)\n",
      "(356,)\n",
      "(86, 64, 64, 64)\n",
      "(86,)\n",
      "(90, 64, 64, 64)\n",
      "(90,)\n",
      "Train:\n",
      "0.2893258426966292 percent of the data has AD label\n",
      "0.41853932584269665 percent of the data has CN label\n",
      "0.29213483146067415 percent of the data has MCI label\n",
      "\n",
      "Validation:\n",
      "0.28888888888888886 percent of the data has AD label\n",
      "0.4222222222222222 percent of the data has CN label\n",
      "0.28888888888888886 percent of the data has MCI label\n",
      "\n",
      "Test\n",
      "0.29069767441860467 percent of the data has AD label\n",
      "0.4186046511627907 percent of the data has CN label\n",
      "0.29069767441860467 percent of the data has MCI label\n"
     ]
    }
   ],
   "source": [
    "\"\"\"  Load in the input - original data \"\"\"\n",
    "\n",
    "Xtr = np.load(\"preprocess/input/random_split/train_data.npy\", allow_pickle = True)\n",
    "ytr = np.load(\"preprocess/input/random_split/train_label.npy\", allow_pickle = True)\n",
    "print(Xtr.shape)\n",
    "print(ytr.shape)\n",
    "\n",
    "Xts = np.load(\"preprocess/input/random_split/test_data.npy\", allow_pickle = True)\n",
    "yts = np.load(\"preprocess/input/random_split/test_label.npy\", allow_pickle = True)\n",
    "print(Xts.shape)\n",
    "print(yts.shape)\n",
    "\n",
    "Xval = np.load(\"preprocess/input/random_split/val_data.npy\", allow_pickle = True)\n",
    "yval = np.load(\"preprocess/input/random_split/val_label.npy\", allow_pickle = True)\n",
    "print(Xval.shape)\n",
    "print(yval.shape)\n",
    "\n",
    "print(\"Train:\")\n",
    "showpercentage(np.unique(ytr, return_counts=True))\n",
    "print()\n",
    "print(\"Validation:\")\n",
    "showpercentage(np.unique(yval, return_counts=True))\n",
    "print()\n",
    "print(\"Test\")\n",
    "showpercentage(np.unique(yts, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_densenet( X_train, y_train, X_valid = None, y_valid = None, \n",
    "             final = False, out = 2,\n",
    "             dr = 0.02, lr = 0.00001, \n",
    "             breg = l2(0.0001), areg = None, \n",
    "             n_epochs = 100, batch_size = 15 ):\n",
    "  \n",
    "    inputs = keras.Input((64, 64, 64, 1))\n",
    "\n",
    "    c1 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(inputs)\n",
    "    \n",
    "#     c1 = cbam(x)\n",
    "#     c1 = add([c1, c1])\n",
    "    c2 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(add([c1, c1]))\n",
    "    c3 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c2)\n",
    "#     c1 = add([c1, x])\n",
    "    p1 = MaxPooling3D(pool_size=(2, 2, 2))(c3)\n",
    "    \n",
    "#     c2 = cbam(c1)\n",
    "#     c3 = add([x, c2])\n",
    "    c4 = add([add([p1, p1]), MaxPooling3D(pool_size=(2, 2, 2))(c1)])\n",
    "    c4 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c4)\n",
    "    c5 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c4)\n",
    "#     c1 = add([c2, c1])\n",
    "    p2 = MaxPooling3D(pool_size=(2, 2, 2))(c5)\n",
    "\n",
    "#     c3 = cbam(c2)\n",
    "#     c5 = add([x, c2])\n",
    "    c6 = add([add([p2, p2]), add([MaxPooling3D(pool_size=(2, 2, 2))(p1), MaxPooling3D(pool_size=(2, 2, 2))(MaxPooling3D(pool_size=(2, 2, 2))(c1))])])\n",
    "    c6 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c6)\n",
    "    c7 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c6)\n",
    "#     c3 = add([c3, c2])\n",
    "    p3 = MaxPooling3D(pool_size=(2, 2, 2))(c7)\n",
    "    \n",
    "#     c4 = cbam(c3)\n",
    "    c8 = add([p3, p3])\n",
    "    c8_1 = add([add([c8, MaxPooling3D(pool_size=(2, 2, 2))(p2)]), add([MaxPooling3D(pool_size=(2, 2, 2))(MaxPooling3D(pool_size=(2, 2, 2))(p1)), MaxPooling3D(pool_size=(2, 2, 2))(MaxPooling3D(pool_size=(2, 2, 2))(MaxPooling3D(pool_size=(2, 2, 2))(c1)))])])\n",
    "    c8 = Conv3D(32, kernel_size=(2,2,2),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c8_1)\n",
    "    c9 = Conv3D(32, kernel_size=(2,2,2),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c8)\n",
    "#     c4 = add([c4, c3])\n",
    "    p4 = MaxPooling3D(pool_size=(2, 2, 2))(add([c8_1, c9]))\n",
    "\n",
    "    x = Dropout(dr)(p4)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, bias_regularizer=breg,   kernel_initializer='he_uniform',activation=\"relu\")(x)\n",
    "    x = Dropout(dr)(x)\n",
    "    x = Dense(256, bias_regularizer=breg,   kernel_initializer='he_uniform',activation=\"relu\")(x)\n",
    "    outputs  = Dense(out, activation='softmax', activity_regularizer=areg)(x)\n",
    "    \n",
    "    model = keras.Model(inputs,outputs , name=\"3ddensenet\")\n",
    "    \n",
    "    opt = Adam(lr = lr)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "    cb = ReduceLROnPlateau(monitor = 'val_loss', \n",
    "                         factor = 0.5, patience = 5, \n",
    "                         verbose = 1, epsilon = 1e-4, mode = 'min')\n",
    "    \n",
    "\n",
    "    hist = model.fit(X_train, y_train,\n",
    "                 batch_size = batch_size, \n",
    "                 epochs = n_epochs,\n",
    "                 callbacks=[cb],\n",
    "                 validation_data = (X_valid, y_valid), \n",
    "                 shuffle = True)\n",
    "    \n",
    "    return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 2]), array([149, 103]))\n",
      "(array([0, 2]), array([38, 26]))\n",
      "(array([0, 2]), array([36, 25]))\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Train on 252 samples, validate on 64 samples\n",
      "Epoch 1/100\n",
      "252/252 [==============================] - 7s 29ms/sample - loss: 6.6072 - acc: 0.4643 - val_loss: 2.0455 - val_acc: 0.6406\n",
      "Epoch 2/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 3.1716 - acc: 0.5119 - val_loss: 2.7003 - val_acc: 0.6094\n",
      "Epoch 3/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 2.4556 - acc: 0.5278 - val_loss: 1.5895 - val_acc: 0.6094\n",
      "Epoch 4/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 1.8535 - acc: 0.6389 - val_loss: 0.7993 - val_acc: 0.5938\n",
      "Epoch 5/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 1.6722 - acc: 0.6349 - val_loss: 0.7841 - val_acc: 0.6250\n",
      "Epoch 6/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 1.5300 - acc: 0.5595 - val_loss: 1.0404 - val_acc: 0.6562\n",
      "Epoch 7/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 1.2372 - acc: 0.6865 - val_loss: 1.0393 - val_acc: 0.6406\n",
      "Epoch 8/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 1.2148 - acc: 0.6627 - val_loss: 1.0061 - val_acc: 0.6406\n",
      "Epoch 9/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 1.2472 - acc: 0.6548 - val_loss: 0.9090 - val_acc: 0.6719\n",
      "Epoch 10/100\n",
      "240/252 [===========================>..] - ETA: 0s - loss: 1.1428 - acc: 0.6625\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "252/252 [==============================] - 7s 27ms/sample - loss: 1.1705 - acc: 0.6548 - val_loss: 1.0026 - val_acc: 0.6562\n",
      "Epoch 11/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.9633 - acc: 0.6944 - val_loss: 0.5524 - val_acc: 0.7500\n",
      "Epoch 12/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.9037 - acc: 0.6944 - val_loss: 0.5494 - val_acc: 0.7500\n",
      "Epoch 13/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.8555 - acc: 0.7103 - val_loss: 0.6093 - val_acc: 0.7344\n",
      "Epoch 14/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 1.0495 - acc: 0.6786 - val_loss: 0.8174 - val_acc: 0.6875\n",
      "Epoch 15/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.9161 - acc: 0.6905 - val_loss: 0.5941 - val_acc: 0.7500\n",
      "Epoch 16/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.6836 - acc: 0.7738 - val_loss: 0.5240 - val_acc: 0.7812\n",
      "Epoch 17/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.7956 - acc: 0.7222 - val_loss: 0.6483 - val_acc: 0.7031\n",
      "Epoch 18/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.7304 - acc: 0.7262 - val_loss: 0.5300 - val_acc: 0.7969\n",
      "Epoch 19/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.8330 - acc: 0.7460 - val_loss: 0.5535 - val_acc: 0.7812\n",
      "Epoch 20/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.7508 - acc: 0.7540 - val_loss: 0.5768 - val_acc: 0.7344\n",
      "Epoch 21/100\n",
      "240/252 [===========================>..] - ETA: 0s - loss: 0.9518 - acc: 0.6833\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.9257 - acc: 0.6944 - val_loss: 0.6383 - val_acc: 0.7344\n",
      "Epoch 22/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.6842 - acc: 0.7937 - val_loss: 0.5014 - val_acc: 0.7656\n",
      "Epoch 23/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.7838 - acc: 0.7421 - val_loss: 0.5211 - val_acc: 0.7656\n",
      "Epoch 24/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.6911 - acc: 0.7540 - val_loss: 0.5330 - val_acc: 0.7656\n",
      "Epoch 25/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.6746 - acc: 0.7778 - val_loss: 0.5004 - val_acc: 0.7656\n",
      "Epoch 26/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.7028 - acc: 0.7302 - val_loss: 0.5155 - val_acc: 0.8125\n",
      "Epoch 27/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.7400 - acc: 0.7540 - val_loss: 0.5023 - val_acc: 0.8125\n",
      "Epoch 28/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.6056 - acc: 0.7778 - val_loss: 0.4779 - val_acc: 0.7969\n",
      "Epoch 29/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.7431 - acc: 0.7460 - val_loss: 0.5138 - val_acc: 0.7969\n",
      "Epoch 30/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.6992 - acc: 0.7421 - val_loss: 0.4946 - val_acc: 0.8125\n",
      "Epoch 31/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5019 - acc: 0.8294 - val_loss: 0.5420 - val_acc: 0.7656\n",
      "Epoch 32/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.6679 - acc: 0.7698 - val_loss: 0.4587 - val_acc: 0.8594\n",
      "Epoch 33/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.6836 - acc: 0.7619 - val_loss: 0.5320 - val_acc: 0.7656\n",
      "Epoch 34/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.7084 - acc: 0.7579 - val_loss: 0.4618 - val_acc: 0.8594\n",
      "Epoch 35/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.6535 - acc: 0.7817 - val_loss: 0.4758 - val_acc: 0.8125\n",
      "Epoch 36/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.6515 - acc: 0.7698 - val_loss: 0.4464 - val_acc: 0.8750\n",
      "Epoch 37/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.4337 - acc: 0.8056 - val_loss: 0.5660 - val_acc: 0.7344\n",
      "Epoch 38/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.6090 - acc: 0.7460 - val_loss: 0.4580 - val_acc: 0.8594\n",
      "Epoch 39/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5083 - acc: 0.7937 - val_loss: 0.4468 - val_acc: 0.8594\n",
      "Epoch 40/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.4719 - acc: 0.8175 - val_loss: 0.5126 - val_acc: 0.7656\n",
      "Epoch 41/100\n",
      "240/252 [===========================>..] - ETA: 0s - loss: 0.6505 - acc: 0.7542\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.6240 - acc: 0.7659 - val_loss: 0.5215 - val_acc: 0.7812\n",
      "Epoch 42/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.6960 - acc: 0.7579 - val_loss: 0.5215 - val_acc: 0.7812\n",
      "Epoch 43/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5424 - acc: 0.8413 - val_loss: 0.4610 - val_acc: 0.8438\n",
      "Epoch 44/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5737 - acc: 0.7698 - val_loss: 0.5089 - val_acc: 0.7812\n",
      "Epoch 45/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5138 - acc: 0.7976 - val_loss: 0.5111 - val_acc: 0.7812\n",
      "Epoch 46/100\n",
      "240/252 [===========================>..] - ETA: 0s - loss: 0.6295 - acc: 0.7875\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.6309 - acc: 0.7897 - val_loss: 0.4518 - val_acc: 0.8594\n",
      "Epoch 47/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5488 - acc: 0.7857 - val_loss: 0.4475 - val_acc: 0.8594\n",
      "Epoch 48/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5861 - acc: 0.7698 - val_loss: 0.4766 - val_acc: 0.8125\n",
      "Epoch 49/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5841 - acc: 0.7738 - val_loss: 0.4528 - val_acc: 0.8438\n",
      "Epoch 50/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5024 - acc: 0.7817 - val_loss: 0.4439 - val_acc: 0.8594\n",
      "Epoch 51/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5562 - acc: 0.7698 - val_loss: 0.4498 - val_acc: 0.8438\n",
      "Epoch 52/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5818 - acc: 0.7619 - val_loss: 0.4641 - val_acc: 0.8438\n",
      "Epoch 53/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.4879 - acc: 0.8333 - val_loss: 0.4308 - val_acc: 0.8906\n",
      "Epoch 54/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5044 - acc: 0.7857 - val_loss: 0.4436 - val_acc: 0.8594\n",
      "Epoch 55/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5949 - acc: 0.7579 - val_loss: 0.4416 - val_acc: 0.8594\n",
      "Epoch 56/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5270 - acc: 0.8095 - val_loss: 0.4598 - val_acc: 0.8438\n",
      "Epoch 57/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.6044 - acc: 0.7659 - val_loss: 0.4701 - val_acc: 0.8281\n",
      "Epoch 58/100\n",
      "240/252 [===========================>..] - ETA: 0s - loss: 0.4758 - acc: 0.7917\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.4752 - acc: 0.7897 - val_loss: 0.4512 - val_acc: 0.8281\n",
      "Epoch 59/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.4312 - acc: 0.8413 - val_loss: 0.4478 - val_acc: 0.8438\n",
      "Epoch 60/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5675 - acc: 0.7778 - val_loss: 0.4336 - val_acc: 0.8594\n",
      "Epoch 61/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5100 - acc: 0.8214 - val_loss: 0.4452 - val_acc: 0.8438\n",
      "Epoch 62/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5148 - acc: 0.8135 - val_loss: 0.4617 - val_acc: 0.8281\n",
      "Epoch 63/100\n",
      "240/252 [===========================>..] - ETA: 0s - loss: 0.5776 - acc: 0.7833\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5876 - acc: 0.7778 - val_loss: 0.4576 - val_acc: 0.8438\n",
      "Epoch 64/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.3810 - acc: 0.8373 - val_loss: 0.4548 - val_acc: 0.8438\n",
      "Epoch 65/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.4445 - acc: 0.8095 - val_loss: 0.4515 - val_acc: 0.8281\n",
      "Epoch 66/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5221 - acc: 0.7857 - val_loss: 0.4576 - val_acc: 0.8438\n",
      "Epoch 67/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.6217 - acc: 0.7500 - val_loss: 0.4579 - val_acc: 0.8438\n",
      "Epoch 68/100\n",
      "240/252 [===========================>..] - ETA: 0s - loss: 0.4300 - acc: 0.8375\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.4151 - acc: 0.8452 - val_loss: 0.4554 - val_acc: 0.8438\n",
      "Epoch 69/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.4940 - acc: 0.7897 - val_loss: 0.4538 - val_acc: 0.8438\n",
      "Epoch 70/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5268 - acc: 0.8056 - val_loss: 0.4475 - val_acc: 0.8438\n",
      "Epoch 71/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.4748 - acc: 0.7857 - val_loss: 0.4475 - val_acc: 0.8438\n",
      "Epoch 72/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5332 - acc: 0.7937 - val_loss: 0.4521 - val_acc: 0.8438\n",
      "Epoch 73/100\n",
      "240/252 [===========================>..] - ETA: 0s - loss: 0.6094 - acc: 0.8042\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5880 - acc: 0.8135 - val_loss: 0.4512 - val_acc: 0.8438\n",
      "Epoch 74/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5846 - acc: 0.7778 - val_loss: 0.4490 - val_acc: 0.8438\n",
      "Epoch 75/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.4671 - acc: 0.8214 - val_loss: 0.4474 - val_acc: 0.8438\n",
      "Epoch 76/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.4733 - acc: 0.8175 - val_loss: 0.4453 - val_acc: 0.8438\n",
      "Epoch 77/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5366 - acc: 0.8016 - val_loss: 0.4427 - val_acc: 0.8438\n",
      "Epoch 78/100\n",
      "240/252 [===========================>..] - ETA: 0s - loss: 0.4737 - acc: 0.8292\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.4946 - acc: 0.8254 - val_loss: 0.4441 - val_acc: 0.8438\n",
      "Epoch 79/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.6684 - acc: 0.7778 - val_loss: 0.4465 - val_acc: 0.8438\n",
      "Epoch 80/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5348 - acc: 0.7579 - val_loss: 0.4485 - val_acc: 0.8438\n",
      "Epoch 81/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5695 - acc: 0.7937 - val_loss: 0.4491 - val_acc: 0.8438\n",
      "Epoch 82/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.6055 - acc: 0.7857 - val_loss: 0.4479 - val_acc: 0.8438\n",
      "Epoch 83/100\n",
      "240/252 [===========================>..] - ETA: 0s - loss: 0.5180 - acc: 0.7750\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5195 - acc: 0.7778 - val_loss: 0.4462 - val_acc: 0.8438\n",
      "Epoch 84/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5080 - acc: 0.7738 - val_loss: 0.4463 - val_acc: 0.8438\n",
      "Epoch 85/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.4925 - acc: 0.7976 - val_loss: 0.4462 - val_acc: 0.8438\n",
      "Epoch 86/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5099 - acc: 0.8175 - val_loss: 0.4452 - val_acc: 0.8438\n",
      "Epoch 87/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5027 - acc: 0.8095 - val_loss: 0.4448 - val_acc: 0.8438\n",
      "Epoch 88/100\n",
      "240/252 [===========================>..] - ETA: 0s - loss: 0.5528 - acc: 0.7792\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-09.\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5316 - acc: 0.7897 - val_loss: 0.4449 - val_acc: 0.8438\n",
      "Epoch 89/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5990 - acc: 0.7778 - val_loss: 0.4448 - val_acc: 0.8438\n",
      "Epoch 90/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.4711 - acc: 0.8413 - val_loss: 0.4448 - val_acc: 0.8438\n",
      "Epoch 91/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5545 - acc: 0.7857 - val_loss: 0.4447 - val_acc: 0.8438\n",
      "Epoch 92/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.6176 - acc: 0.7738 - val_loss: 0.4447 - val_acc: 0.8438\n",
      "Epoch 93/100\n",
      "240/252 [===========================>..] - ETA: 0s - loss: 0.5487 - acc: 0.8125\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-09.\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5509 - acc: 0.8135 - val_loss: 0.4447 - val_acc: 0.8438\n",
      "Epoch 94/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.4653 - acc: 0.8135 - val_loss: 0.4448 - val_acc: 0.8438\n",
      "Epoch 95/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5291 - acc: 0.7778 - val_loss: 0.4448 - val_acc: 0.8438\n",
      "Epoch 96/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5262 - acc: 0.8135 - val_loss: 0.4447 - val_acc: 0.8438\n",
      "Epoch 97/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5578 - acc: 0.8135 - val_loss: 0.4448 - val_acc: 0.8438\n",
      "Epoch 98/100\n",
      "240/252 [===========================>..] - ETA: 0s - loss: 0.6108 - acc: 0.7542\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-09.\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.5953 - acc: 0.7540 - val_loss: 0.4447 - val_acc: 0.8438\n",
      "Epoch 99/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.4850 - acc: 0.8175 - val_loss: 0.4447 - val_acc: 0.8438\n",
      "Epoch 100/100\n",
      "252/252 [==============================] - 6s 26ms/sample - loss: 0.4554 - acc: 0.8175 - val_loss: 0.4447 - val_acc: 0.8438\n"
     ]
    }
   ],
   "source": [
    "# create input for binary classification of NC vs. AD\n",
    "Xtr_ncad, ytr_ncad = data_filter(Xtr, ytr, 1)\n",
    "Xval_ncad, yval_ncad = data_filter(Xval, yval, 1)\n",
    "Xts_ncad, yts_ncad = data_filter(Xts, yts, 1)\n",
    "\n",
    "# reshape the input\n",
    "X_train = Xtr_ncad.reshape(-1,64,64,64,1) \n",
    "X_test = Xts_ncad.reshape(-1,64,64,64,1) \n",
    "X_val = Xval_ncad.reshape(-1,64,64,64,1) \n",
    "\n",
    "\n",
    "# one hot encode the target labels \n",
    "y_train = onehot_bi(ytr_ncad)\n",
    "y_test = onehot_bi(yts_ncad)\n",
    "y_val = onehot_bi(yval_ncad)\n",
    "\n",
    "\n",
    "\n",
    "# model training\n",
    "model, hist = get_densenet(X_train, y_train, X_val, y_val, \n",
    "                       breg = l2(0.001), areg = l1(0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn(out = 2,\n",
    "             dr = 0.02, lr = 0.00001, \n",
    "             breg = l2(0.0001), areg = None):\n",
    "    inputs = keras.Input((64, 64, 64, 1))\n",
    "\n",
    "    x = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(inputs)\n",
    "    \n",
    "#     c1 = cbam(x)\n",
    "    c1 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(x)\n",
    "    c1 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c1)\n",
    "#     c1 = add([c1, x])\n",
    "    c1 = MaxPooling3D(pool_size=(2, 2, 2))(c1)\n",
    "    \n",
    "#     c2 = cbam(c1)\n",
    "    c2 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c1)\n",
    "    c2 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c2)\n",
    "#     c1 = add([c2, c1])\n",
    "    c2 = MaxPooling3D(pool_size=(2, 2, 2))(c2)\n",
    "\n",
    "#     c3 = cbam(c2)\n",
    "    c3 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c2)\n",
    "    c3 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c3)\n",
    "#     c3 = add([c3, c2])\n",
    "    c3 = MaxPooling3D(pool_size=(2, 2, 2))(c3)\n",
    "    \n",
    "#     c4 = cbam(c3)\n",
    "    c4 = Conv3D(32, kernel_size=(2,2,2),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c3)\n",
    "    c4 = Conv3D(32, kernel_size=(2,2,2),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c4)\n",
    "#     c4 = add([c4, c3])\n",
    "    c4 = MaxPooling3D(pool_size=(2, 2, 2))(c4)\n",
    "\n",
    "    x = Dropout(dr)(c4)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, bias_regularizer=breg,   kernel_initializer='he_uniform',activation=\"relu\")(x)\n",
    "    x = Dropout(dr)(x)\n",
    "    x = Dense(256, bias_regularizer=breg,   kernel_initializer='he_uniform',activation=\"relu\")(x)\n",
    "    outputs  = Dense(out, activation='softmax', activity_regularizer=areg)(x)\n",
    "    \n",
    "    model = keras.Model(inputs,outputs , name=\"3dcnn\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dense(out = 2,\n",
    "             dr = 0.02, lr = 0.00001, \n",
    "             breg = l2(0.0001), areg = None):\n",
    "    inputs = keras.Input((64, 64, 64, 1))\n",
    "\n",
    "    c1 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(inputs)\n",
    "    \n",
    "#     c1 = cbam(x)\n",
    "#     c1 = add([c1, c1])\n",
    "    c2 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(add([c1, c1]))\n",
    "    c3 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c2)\n",
    "#     c1 = add([c1, x])\n",
    "    p1 = MaxPooling3D(pool_size=(2, 2, 2))(c3)\n",
    "    \n",
    "#     c2 = cbam(c1)\n",
    "#     c3 = add([x, c2])\n",
    "    c4 = add([add([p1, p1]), MaxPooling3D(pool_size=(2, 2, 2))(c1)])\n",
    "    c4 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c4)\n",
    "    c5 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c4)\n",
    "#     c1 = add([c2, c1])\n",
    "    p2 = MaxPooling3D(pool_size=(2, 2, 2))(c5)\n",
    "\n",
    "#     c3 = cbam(c2)\n",
    "#     c5 = add([x, c2])\n",
    "    c6 = add([add([p2, p2]), add([MaxPooling3D(pool_size=(2, 2, 2))(p1), MaxPooling3D(pool_size=(2, 2, 2))(MaxPooling3D(pool_size=(2, 2, 2))(c1))])])\n",
    "    c6 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c6)\n",
    "    c7 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c6)\n",
    "#     c3 = add([c3, c2])\n",
    "    p3 = MaxPooling3D(pool_size=(2, 2, 2))(c7)\n",
    "    \n",
    "#     c4 = cbam(c3)\n",
    "    c8 = add([p3, p3])\n",
    "    c8_1 = add([add([c8, MaxPooling3D(pool_size=(2, 2, 2))(p2)]), add([MaxPooling3D(pool_size=(2, 2, 2))(MaxPooling3D(pool_size=(2, 2, 2))(p1)), MaxPooling3D(pool_size=(2, 2, 2))(MaxPooling3D(pool_size=(2, 2, 2))(MaxPooling3D(pool_size=(2, 2, 2))(c1)))])])\n",
    "    c8 = Conv3D(32, kernel_size=(2,2,2),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c8_1)\n",
    "    c9 = Conv3D(32, kernel_size=(2,2,2),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c8)\n",
    "#     c4 = add([c4, c3])\n",
    "    p4 = MaxPooling3D(pool_size=(2, 2, 2))(c9)\n",
    "\n",
    "    x = Dropout(dr)(p4)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, bias_regularizer=breg,   kernel_initializer='he_uniform',activation=\"relu\")(x)\n",
    "    x = Dropout(dr)(x)\n",
    "    x = Dense(256, bias_regularizer=breg,   kernel_initializer='he_uniform',activation=\"relu\")(x)\n",
    "    outputs  = Dense(out, activation='softmax', activity_regularizer=areg)(x)\n",
    "    \n",
    "    model = keras.Model(inputs,outputs , name=\"3dcnn\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_18 (InputLayer)           (None, 64, 64, 64, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_127 (Conv3D)             (None, 64, 64, 64, 3 896         input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_53 (Add)                    (None, 64, 64, 64, 3 0           conv3d_127[0][0]                 \n",
      "                                                                 conv3d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_128 (Conv3D)             (None, 64, 64, 64, 3 27680       add_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_129 (Conv3D)             (None, 64, 64, 64, 3 27680       conv3d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_85 (MaxPooling3D) (None, 32, 32, 32, 3 0           conv3d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_54 (Add)                    (None, 32, 32, 32, 3 0           max_pooling3d_85[0][0]           \n",
      "                                                                 max_pooling3d_85[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_86 (MaxPooling3D) (None, 32, 32, 32, 3 0           conv3d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_55 (Add)                    (None, 32, 32, 32, 3 0           add_54[0][0]                     \n",
      "                                                                 max_pooling3d_86[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_130 (Conv3D)             (None, 32, 32, 32, 3 27680       add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_131 (Conv3D)             (None, 32, 32, 32, 3 27680       conv3d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_90 (MaxPooling3D) (None, 32, 32, 32, 3 0           conv3d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_87 (MaxPooling3D) (None, 16, 16, 16, 3 0           conv3d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_88 (MaxPooling3D) (None, 16, 16, 16, 3 0           max_pooling3d_85[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_89 (MaxPooling3D) (None, 16, 16, 16, 3 0           max_pooling3d_90[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_56 (Add)                    (None, 16, 16, 16, 3 0           max_pooling3d_87[0][0]           \n",
      "                                                                 max_pooling3d_87[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_57 (Add)                    (None, 16, 16, 16, 3 0           max_pooling3d_88[0][0]           \n",
      "                                                                 max_pooling3d_89[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_58 (Add)                    (None, 16, 16, 16, 3 0           add_56[0][0]                     \n",
      "                                                                 add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_132 (Conv3D)             (None, 16, 16, 16, 3 27680       add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_133 (Conv3D)             (None, 16, 16, 16, 3 27680       conv3d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_97 (MaxPooling3D) (None, 32, 32, 32, 3 0           conv3d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_91 (MaxPooling3D) (None, 8, 8, 8, 32)  0           conv3d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_94 (MaxPooling3D) (None, 16, 16, 16, 3 0           max_pooling3d_85[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_96 (MaxPooling3D) (None, 16, 16, 16, 3 0           max_pooling3d_97[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_59 (Add)                    (None, 8, 8, 8, 32)  0           max_pooling3d_91[0][0]           \n",
      "                                                                 max_pooling3d_91[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_92 (MaxPooling3D) (None, 8, 8, 8, 32)  0           max_pooling3d_87[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_93 (MaxPooling3D) (None, 8, 8, 8, 32)  0           max_pooling3d_94[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_95 (MaxPooling3D) (None, 8, 8, 8, 32)  0           max_pooling3d_96[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_60 (Add)                    (None, 8, 8, 8, 32)  0           add_59[0][0]                     \n",
      "                                                                 max_pooling3d_92[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_61 (Add)                    (None, 8, 8, 8, 32)  0           max_pooling3d_93[0][0]           \n",
      "                                                                 max_pooling3d_95[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_62 (Add)                    (None, 8, 8, 8, 32)  0           add_60[0][0]                     \n",
      "                                                                 add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_134 (Conv3D)             (None, 8, 8, 8, 32)  8224        add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_135 (Conv3D)             (None, 8, 8, 8, 32)  8224        conv3d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_98 (MaxPooling3D) (None, 4, 4, 4, 32)  0           conv3d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 4, 4, 4, 32)  0           max_pooling3d_98[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 2048)         0           dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 512)          1049088     flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 512)          0           dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 256)          131328      dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 2)            514         dense_37[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,364,354\n",
      "Trainable params: 1,364,354\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=get_dense()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet( X_train, y_train, X_valid = None, y_valid = None, \n",
    "             final = False, out = 2,\n",
    "             dr = 0.02, lr = 0.00001, \n",
    "             breg = l2(0.0001), areg = None, \n",
    "             n_epochs = 100, batch_size = 15 ):\n",
    "  \n",
    "    inputs = keras.Input((64, 64, 64, 1))\n",
    "\n",
    "    x = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(inputs)\n",
    "\n",
    "    c1 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(x)\n",
    "    c1_1 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c1)\n",
    "    c1_1 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c1_1)\n",
    "    c1_1 = add([c1, c1_1])\n",
    "    c1_1 = MaxPooling3D(pool_size=(2, 2, 2))(c1_1)\n",
    "    \n",
    "    c2 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c1)\n",
    "    c2_2 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c2)\n",
    "    c2_2 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c2_2)\n",
    "    c2_2 = add([c2, c2_2])\n",
    "    c2_2 = MaxPooling3D(pool_size=(2, 2, 2))(c2_2)\n",
    "\n",
    "    c3 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c2)\n",
    "    c3_3 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c3)\n",
    "    c3_3 = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c3_3)\n",
    "    c3_3 = add([c3, c3_3])\n",
    "    c3_3 = MaxPooling3D(pool_size=(2, 2, 2))(c3_3)\n",
    "\n",
    "    c4 = Conv3D(32, kernel_size=(2,2,2),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c3)\n",
    "    c4_4 = Conv3D(32, kernel_size=(2,2,2),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c4)\n",
    "    c4_4 = Conv3D(32, kernel_size=(2,2,2),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(c4_4)\n",
    "    c4_4 = add([c4, c4_4])\n",
    "    c4_4 = MaxPooling3D(pool_size=(2, 2, 2))(c4_4)\n",
    "\n",
    "    x = Dropout(dr)(c4_4)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, bias_regularizer=breg,   kernel_initializer='he_uniform',activation=\"relu\")(x)\n",
    "    x = Dropout(dr)(x)\n",
    "    x = Dense(256, bias_regularizer=breg,   kernel_initializer='he_uniform',activation=\"relu\")(x)\n",
    "    outputs  = Dense(out, activation='softmax', activity_regularizer=areg)(x)\n",
    "    \n",
    "    model = keras.Model(inputs,outputs , name=\"3dresnet\")\n",
    "    \n",
    "    opt = Adam(lr = lr)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "    cb = ReduceLROnPlateau(monitor = 'val_loss', \n",
    "                         factor = 0.5, patience = 5, \n",
    "                         verbose = 1, epsilon = 1e-4, mode = 'min')\n",
    "    \n",
    "\n",
    "    hist = model.fit(X_train, y_train,\n",
    "                 batch_size = batch_size, \n",
    "                 epochs = n_epochs,\n",
    "                 callbacks=[cb],\n",
    "                 validation_data = (X_valid, y_valid), \n",
    "                 shuffle = True)\n",
    "    \n",
    "    return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 2]), array([149, 103]))\n",
      "(array([0, 2]), array([38, 26]))\n",
      "(array([0, 2]), array([36, 25]))\n",
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Train on 252 samples, validate on 64 samples\n",
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "252/252 [==============================] - 20s 78ms/sample - loss: 3.4064 - acc: 0.5357 - val_loss: 0.6118 - val_acc: 0.6719\n",
      "Epoch 2/100\n",
      "252/252 [==============================] - 13s 53ms/sample - loss: 0.6717 - acc: 0.6667 - val_loss: 0.4549 - val_acc: 0.8594\n",
      "Epoch 3/100\n",
      "252/252 [==============================] - 13s 53ms/sample - loss: 0.7113 - acc: 0.6944 - val_loss: 0.5008 - val_acc: 0.7188\n",
      "Epoch 4/100\n",
      "252/252 [==============================] - 13s 53ms/sample - loss: 0.3961 - acc: 0.8294 - val_loss: 0.6821 - val_acc: 0.5469\n",
      "Epoch 5/100\n",
      "252/252 [==============================] - 13s 53ms/sample - loss: 0.3664 - acc: 0.8532 - val_loss: 0.4073 - val_acc: 0.8125\n",
      "Epoch 6/100\n",
      "252/252 [==============================] - 13s 53ms/sample - loss: 0.1984 - acc: 0.9365 - val_loss: 0.2495 - val_acc: 0.9375\n",
      "Epoch 7/100\n",
      "252/252 [==============================] - 13s 53ms/sample - loss: 0.1439 - acc: 0.9722 - val_loss: 0.3586 - val_acc: 0.8125\n",
      "Epoch 8/100\n",
      "252/252 [==============================] - 13s 53ms/sample - loss: 0.2824 - acc: 0.8611 - val_loss: 0.3102 - val_acc: 0.8750\n",
      "Epoch 9/100\n",
      "252/252 [==============================] - 13s 53ms/sample - loss: 0.1586 - acc: 0.9524 - val_loss: 0.2254 - val_acc: 0.9219\n",
      "Epoch 10/100\n",
      "252/252 [==============================] - 13s 53ms/sample - loss: 0.0886 - acc: 0.9802 - val_loss: 0.2477 - val_acc: 0.9062\n",
      "Epoch 11/100\n",
      "252/252 [==============================] - 13s 53ms/sample - loss: 0.0752 - acc: 0.9841 - val_loss: 0.1226 - val_acc: 0.9844\n",
      "Epoch 12/100\n",
      "252/252 [==============================] - 13s 53ms/sample - loss: 0.0502 - acc: 0.9960 - val_loss: 0.1130 - val_acc: 0.9688\n",
      "Epoch 13/100\n",
      "252/252 [==============================] - 13s 53ms/sample - loss: 0.0400 - acc: 0.9960 - val_loss: 0.1017 - val_acc: 0.9844\n",
      "Epoch 14/100\n",
      "252/252 [==============================] - 13s 53ms/sample - loss: 0.0361 - acc: 0.9960 - val_loss: 0.0916 - val_acc: 0.9844\n",
      "Epoch 15/100\n",
      "252/252 [==============================] - 13s 53ms/sample - loss: 0.0277 - acc: 1.0000 - val_loss: 0.0839 - val_acc: 0.9844\n",
      "Epoch 16/100\n",
      "252/252 [==============================] - 13s 53ms/sample - loss: 0.0235 - acc: 1.0000 - val_loss: 0.0879 - val_acc: 0.9688\n",
      "Epoch 17/100\n",
      "135/252 [===============>..............] - ETA: 5s - loss: 0.0198 - acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cf48aa2fdabd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# model training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m model, hist = get_resnet(X_train, y_train, X_val, y_val, \n\u001b[0;32m---> 21\u001b[0;31m                        breg = l2(0.001), areg = l1(0.001))\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-0a0158770983>\u001b[0m in \u001b[0;36mget_resnet\u001b[0;34m(X_train, y_train, X_valid, y_valid, final, out, dr, lr, breg, areg, n_epochs, batch_size)\u001b[0m\n\u001b[1;32m     55\u001b[0m                  \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                  \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                  shuffle = True)\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create input for binary classification of NC vs. AD\n",
    "Xtr_ncad, ytr_ncad = data_filter(Xtr, ytr, 1)\n",
    "Xval_ncad, yval_ncad = data_filter(Xval, yval, 1)\n",
    "Xts_ncad, yts_ncad = data_filter(Xts, yts, 1)\n",
    "\n",
    "# reshape the input\n",
    "X_train = Xtr_ncad.reshape(-1,64,64,64,1) \n",
    "X_test = Xts_ncad.reshape(-1,64,64,64,1) \n",
    "X_val = Xval_ncad.reshape(-1,64,64,64,1) \n",
    "\n",
    "\n",
    "# one hot encode the target labels \n",
    "y_train = onehot_bi(ytr_ncad)\n",
    "y_test = onehot_bi(yts_ncad)\n",
    "y_val = onehot_bi(yval_ncad)\n",
    "\n",
    "\n",
    "\n",
    "# model training\n",
    "model, hist = get_resnet(X_train, y_train, X_val, y_val, \n",
    "                       breg = l2(0.001), areg = l1(0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 64, 64, 64, 1)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 64, 64, 64, 32)    896       \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 64, 64, 64, 32)    27680     \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 64, 64, 64, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 32, 32, 32, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_12 (Conv3D)           (None, 32, 32, 32, 32)    27680     \n",
      "_________________________________________________________________\n",
      "conv3d_13 (Conv3D)           (None, 32, 32, 32, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 16, 16, 16, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_14 (Conv3D)           (None, 16, 16, 16, 32)    27680     \n",
      "_________________________________________________________________\n",
      "conv3d_15 (Conv3D)           (None, 16, 16, 16, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 8, 8, 8, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_16 (Conv3D)           (None, 8, 8, 8, 32)       8224      \n",
      "_________________________________________________________________\n",
      "conv3d_17 (Conv3D)           (None, 8, 8, 8, 32)       8224      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 4, 4, 4, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 4, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 1,364,354\n",
      "Trainable params: 1,364,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=get_cnn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbam(inputs):\n",
    "    inputs_channels=int(inputs.shape[-1])\n",
    "    x=GlobalAveragePooling3D()(inputs)\n",
    "    x=Dense(int(inputs_channels/4),activation=\"relu\")(x)\n",
    "    x=Dense(int(inputs_channels),activation=\"softmax\")(x)\n",
    "    x=Reshape((1,1,1,inputs_channels))(x)\n",
    "    x=Multiply()([inputs,x])\n",
    "    return x\n",
    "def get_voxcnn( X_train, y_train, X_valid = None, y_valid = None, \n",
    "             final = False, out = 2,\n",
    "             dr = 0.02, lr = 0.00001, \n",
    "             breg = l2(0.0001), areg = None, \n",
    "             n_epochs = 100, batch_size = 15 ):\n",
    "  \n",
    "    inputs = keras.Input((64, 64, 64, 1))\n",
    "\n",
    "    x = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(inputs)\n",
    "    \n",
    "    x = cbam(x)\n",
    "    x = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(x)\n",
    "    x = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "    \n",
    "    x = cbam(x)\n",
    "    x = Conv3D(64, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(x)\n",
    "    x = Conv3D(64, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "    \n",
    "    x = cbam(x)\n",
    "    x = Conv3D(128, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(x)\n",
    "    x = Conv3D(128, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "    \n",
    "    x = cbam(x)\n",
    "    x = Conv3D(256, kernel_size=(2,2,2),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(x)\n",
    "    x = Conv3D(256, kernel_size=(2,2,2),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "\n",
    "    x = Dropout(dr)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, bias_regularizer=breg,   kernel_initializer='he_uniform',activation=\"relu\")(x)\n",
    "    x = Dropout(dr)(x)\n",
    "    x = Dense(256, bias_regularizer=breg,   kernel_initializer='he_uniform',activation=\"relu\")(x)\n",
    "    outputs  = Dense(out, activation='softmax', activity_regularizer=areg)(x)\n",
    "    \n",
    "    model = keras.Model(inputs,outputs , name=\"3dcnn\")\n",
    "    \n",
    "    opt = Adam(lr = lr)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "    cb = ReduceLROnPlateau(monitor = 'val_loss', \n",
    "                         factor = 0.5, patience = 5, \n",
    "                         verbose = 1, epsilon = 1e-4, mode = 'min')\n",
    "    \n",
    "\n",
    "    hist = model.fit(X_train, y_train,\n",
    "                 batch_size = batch_size, \n",
    "                 epochs = n_epochs,\n",
    "                 callbacks=[cb],\n",
    "                 validation_data = (X_valid, y_valid), \n",
    "                 shuffle = True)\n",
    "    \n",
    "    return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn( X_train, y_train, X_valid = None, y_valid = None, \n",
    "             final = False, out = 2,\n",
    "             dr = 0.02, lr = 0.00001, \n",
    "             breg = l2(0.0001), areg = None, \n",
    "             n_epochs = 100, batch_size = 15 ):\n",
    "  \n",
    "    inputs = keras.Input((64, 64, 64, 1))\n",
    "\n",
    "    x = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(inputs)\n",
    "    \n",
    "#     x = cbam(x)\n",
    "    x = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(x)\n",
    "    x = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "    \n",
    "#     x = cbam(x)\n",
    "    x = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(x)\n",
    "    x = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "    \n",
    "#     x = cbam(x)\n",
    "    x = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(x)\n",
    "    x = Conv3D(32, kernel_size=(3,3,3),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "    \n",
    "#     x = cbam(x)\n",
    "    x = Conv3D(32, kernel_size=(2,2,2),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(x)\n",
    "    x = Conv3D(32, kernel_size=(2,2,2),  kernel_initializer='he_uniform', padding=\"same\",activation=\"relu\", bias_regularizer=breg)(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "\n",
    "    x = Dropout(dr)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, bias_regularizer=breg,   kernel_initializer='he_uniform',activation=\"relu\")(x)\n",
    "    x = Dropout(dr)(x)\n",
    "    x = Dense(256, bias_regularizer=breg,   kernel_initializer='he_uniform',activation=\"relu\")(x)\n",
    "    outputs  = Dense(out, activation='softmax', activity_regularizer=areg)(x)\n",
    "    \n",
    "    model = keras.Model(inputs,outputs , name=\"3dcnn\")\n",
    "    \n",
    "    opt = Adam(lr = lr)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "    cb = ReduceLROnPlateau(monitor = 'val_loss', \n",
    "                         factor = 0.5, patience = 5, \n",
    "                         verbose = 1, epsilon = 1e-4, mode = 'min')\n",
    "    \n",
    "\n",
    "    hist = model.fit(X_train, y_train,\n",
    "                 batch_size = batch_size, \n",
    "                 epochs = n_epochs,\n",
    "                 callbacks=[cb],\n",
    "                 validation_data = (X_valid, y_valid), \n",
    "                 shuffle = True)\n",
    "    \n",
    "    return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 2]), array([149, 103]))\n",
      "(array([0, 2]), array([38, 26]))\n",
      "(array([0, 2]), array([36, 25]))\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Train on 252 samples, validate on 64 samples\n",
      "Epoch 1/100\n",
      "252/252 [==============================] - 7s 27ms/sample - loss: 0.7652 - acc: 0.5119 - val_loss: 0.6828 - val_acc: 0.5938\n",
      "Epoch 2/100\n",
      "252/252 [==============================] - 6s 24ms/sample - loss: 0.7071 - acc: 0.5952 - val_loss: 0.6657 - val_acc: 0.5938\n",
      "Epoch 3/100\n",
      "252/252 [==============================] - 6s 24ms/sample - loss: 0.6809 - acc: 0.6071 - val_loss: 0.6599 - val_acc: 0.5938\n",
      "Epoch 4/100\n",
      "252/252 [==============================] - 6s 24ms/sample - loss: 0.6551 - acc: 0.6151 - val_loss: 0.6529 - val_acc: 0.5938\n",
      "Epoch 5/100\n",
      "252/252 [==============================] - 6s 24ms/sample - loss: 0.6554 - acc: 0.6032 - val_loss: 0.6484 - val_acc: 0.5938\n",
      "Epoch 6/100\n",
      "252/252 [==============================] - 6s 24ms/sample - loss: 0.6361 - acc: 0.6468 - val_loss: 0.6394 - val_acc: 0.5938\n",
      "Epoch 7/100\n",
      "252/252 [==============================] - 6s 24ms/sample - loss: 0.6292 - acc: 0.6389 - val_loss: 0.6335 - val_acc: 0.6094\n",
      "Epoch 8/100\n",
      "225/252 [=========================>....] - ETA: 0s - loss: 0.6240 - acc: 0.6533"
     ]
    }
   ],
   "source": [
    "# create input for binary classification of NC vs. AD\n",
    "Xtr_ncad, ytr_ncad = data_filter(Xtr, ytr, 1)\n",
    "Xval_ncad, yval_ncad = data_filter(Xval, yval, 1)\n",
    "Xts_ncad, yts_ncad = data_filter(Xts, yts, 1)\n",
    "\n",
    "# reshape the input\n",
    "X_train = Xtr_ncad.reshape(-1,64,64,64,1) \n",
    "X_test = Xts_ncad.reshape(-1,64,64,64,1) \n",
    "X_val = Xval_ncad.reshape(-1,64,64,64,1) \n",
    "\n",
    "\n",
    "# one hot encode the target labels \n",
    "y_train = onehot_bi(ytr_ncad)\n",
    "y_test = onehot_bi(yts_ncad)\n",
    "y_val = onehot_bi(yval_ncad)\n",
    "\n",
    "\n",
    "\n",
    "# model training\n",
    "model, hist = get_cnn(X_train, y_train, X_val, y_val, \n",
    "                       breg = l2(0.001), areg = l1(0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-1.13.1",
   "language": "python",
   "name": "tensorflow-1.13.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
